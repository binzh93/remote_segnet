# -*- coding: utf8 -*-
import tensorflow as tf
import numpy as np
import time
import gdal
from Inputs import read_batch, read_bacth_multifile
from datamake import write_tiff, writeTiff


class SegNet():
    def __init__(self, num_epochs, learning_rate, learning_rate_decay, moving_average_decay):
        self.num_epochs = num_epochs
        self.learning_rate = learning_rate
        self.learning_rate_decay = learning_rate_decay
        self.moving_average_decay = moving_average_decay

    # batch normalization
    def batch_normalization(self, input, isTraining, name):
        return tf.cond(isTraining,
                       lambda: tf.contrib.layers.batch_norm(input, is_training=isTraining, scope=name + '_bn'),
                       lambda: tf.contrib.layers.batch_norm(input, is_training=isTraining, scope=name + '_bn',
                                                            reuse=True))  # reuse=True

    def conv_op(self, input, kernel_shape, stride, isTraining, activation=True, name=None):
        depth = kernel_shape[3]
        with tf.variable_scope('conv' + name) as scope:

            kernel = tf.get_variable('conv-kernel', shape=kernel_shape,
                                     initializer=tf.contrib.layers.xavier_initializer_conv2d())  # attention
            '''
            kernel = tf.get_variable('conv-kernel', shape=kernel_shape,
                                     initializer=tf.truncated_normal_initializer(stddev=0.1))  # attention
            '''

            biases = tf.get_variable('conv-biases', shape=[depth],
                                     initializer=tf.constant_initializer(0.0))
            conv = tf.nn.conv2d(input, kernel, strides=[1, stride, stride, 1], padding='SAME', name=scope.name)
            layer = tf.nn.bias_add(conv, biases)

        if activation is True:
            relu_val = tf.nn.relu(self.batch_normalization(layer, isTraining, scope.name))
        else:
            relu_val = self.batch_normalization(layer, isTraining, scope.name)
        return relu_val

    def deconv_op(self, input, kernel_shape, out_shape, stride, isTraining, activation=True, name=None):
        # attention kernel_shape's [2] [3] is changed, cause it's deconvolution
        depth = kernel_shape[2]
        with tf.variable_scope('deconv' + name) as scope:
            kernel = tf.get_variable('deconv-kernel', shape=kernel_shape,
                                     initializer=tf.contrib.layers.xavier_initializer_conv2d())  # attention
            '''
            kernel = tf.get_variable('deconv-kernel', shape=kernel_shape, initializer=tf.truncated_normal_initializer(stddev=0.1)) 
            '''

            biases = tf.get_variable('deconv-biases', shape=[depth],
                                     initializer=tf.constant_initializer(0.0))

            deconv = tf.nn.conv2d_transpose(input, kernel, out_shape, strides=[1, stride, stride, 1],
                                            padding='SAME',
                                            name=scope.name)
            layer = tf.nn.bias_add(deconv, biases)
        if activation is True:
            relu_val = tf.nn.relu(self.batch_normalization(layer, isTraining, scope.name))
        else:
            relu_val = self.batch_normalization(layer, isTraining, scope.name)
        return relu_val

    def max_pool_with_argmax_op(self, input, stride, name):
        # tf.nn.max_pool_with_argmax, only GPU-supported, tf.nn.max_pool_with_argmax_and_mask seem to high version support
        return tf.nn.max_pool_with_argmax(input, ksize=[1, 2, 2, 1], strides=[1, stride, stride, 1], padding='SAME', name=name)

    def unpool(self, net, mask, stride, name):
        assert mask is not None
        with tf.name_scope(name):
            ksize = [1, stride, stride, 1]
            input_shape = net.get_shape().as_list()
            #  calculation new shape
            output_shape = (input_shape[0], input_shape[1] * ksize[1], input_shape[2] * ksize[2], input_shape[3])
            # calculation indices for batch, height, width and feature maps
            one_like_mask = tf.ones_like(mask)
            batch_range = tf.reshape(tf.range(output_shape[0], dtype=tf.int64), shape=[input_shape[0], 1, 1, 1])
            b = one_like_mask * batch_range
            y = mask // (output_shape[2] * output_shape[3])
            x = mask % (output_shape[2] * output_shape[3]) // output_shape[3]
            feature_range = tf.range(output_shape[3], dtype=tf.int64)
            f = one_like_mask * feature_range
            # transpose indices & reshape update values to one dimension
            updates_size = tf.size(net)
            indices = tf.transpose(tf.reshape(tf.stack([b, y, x, f]), [4, updates_size]))
            values = tf.reshape(net, [updates_size])
            ret = tf.scatter_nd(indices, values, output_shape)
            return ret

    def inference(self, images, batch_size, isTraining):
        # Local Response Normalization(局部响应归一化), 这里参数位经验值，论文中推荐的参数
        # 试一下，后期使用全局归一化的方法
        img_lrn = tf.nn.lrn(images, depth_radius=5, bias=1.0, alpha=0.0001, beta=0.75, name='img_lrn')

        # encode
        conv1_1 = self.conv_op(img_lrn, [3, 3, img_lrn.get_shape().as_list()[3], 64], stride=1, isTraining=isTraining, name='1_1')  # 224*224*8  -> 224*224*64
        pool1, arg1 = self.max_pool_with_argmax_op(conv1_1, stride=2, name='pool1')  # 112*112*64

        conv2_1 = self.conv_op(pool1, [3, 3, 64, 128], stride=1, isTraining=isTraining, name='2_1')  # 112*112*128
        pool2, arg2 = self.max_pool_with_argmax_op(conv2_1, stride=2, name='pool2')  # 56*56*128

        conv3_1 = self.conv_op(pool2, [3, 3, 128, 256], stride=1, isTraining=isTraining, name='3_1')  # 56*56*256
        pool3, arg3 = self.max_pool_with_argmax_op(conv3_1, stride=2, name='pool3')  # 28*28*256

        conv4_1 = self.conv_op(pool3, [3, 3, 256, 512], stride=1, isTraining=isTraining, name='4_1')  # 28*28*512
        pool4, arg4 = self.max_pool_with_argmax_op(conv4_1, stride=2, name='pool4')  # 14*14*512
        # conv5_1 = self.conv_op(pool4, [3, 3, 512, 512], stride=1, isTraining=isTraining, name='5_1')  # 14*14*512

        # decode
        unsampling1 = self.unpool(pool4, arg4, stride=2, name='unsampling1')  # 28*28*512
        deconv1 = self.deconv_op(unsampling1, [3, 3, 256, 512], [batch_size, 28, 28, 256], stride=1, isTraining=isTraining, name='un1')  # 28*28*256
        conv_decode1_1 = self.conv_op(deconv1, [3, 3, 256, 256], stride=1, isTraining=isTraining, activation=False, name='de1_1')  # 28*28*256

        unsampling2 = self.unpool(conv_decode1_1, arg3, stride=2, name='unsampling2')  # 56*56*256
        deconv2 = self.deconv_op(unsampling2, [3, 3, 128, 256], [batch_size, 56, 56, 128], stride=1, isTraining=isTraining, name='un2')  # 56*56*128
        conv_decode2_1 = self.conv_op(deconv2, [3, 3, 128, 128], stride=1, isTraining=isTraining, activation=False, name='de2_1')  # 56*56*128

        unsampling3 = self.unpool(conv_decode2_1, arg2, stride=2, name='unsampling3')  # 112*112*128
        deconv3_1 = self.deconv_op(unsampling3, [3, 3, 64, 128], [batch_size, 112, 112, 64], stride=1, isTraining=isTraining, name='un3')  # 112*112*128
        conv_decode3_1 = self.conv_op(deconv3_1, [3, 3, 64, 64], stride=1, isTraining=isTraining, activation=False, name='de3_1')  # 112*112*64

        unsampling4 = self.unpool(conv_decode3_1, arg1, stride=2, name='unsampling4')  # 224*224*64
        deconv4 = self.deconv_op(unsampling4, [3, 3, 64, 64], [batch_size, 224, 224, 64], stride=1, isTraining=isTraining, name='un4')  # 112*112*64
        conv_decode4_1 = self.conv_op(deconv4, [3, 3, 64, 64], stride=1, isTraining=isTraining, activation=False, name='de4_1')  # 28*28*512

        # classifier
        with tf.variable_scope('conv-classifier'):
            kernel = tf.get_variable('kernel-classifier', shape=[3, 3, 64, 2], initializer=tf.contrib.layers.xavier_initializer_conv2d())  # attention
            '''
            kernel = tf.get_variable('conv-kernel', shape=kernel_shape, initializer=tf.truncated_normal_initializer(stddev=0.1))  
            '''

            biases = tf.get_variable('biases-classifier', shape=2, initializer=tf.constant_initializer(0.0))
            conv = tf.nn.conv2d(conv_decode4_1, kernel, strides=[1, 1, 1, 1], padding='SAME', name='conv-classifier')
            classifier = tf.nn.bias_add(conv, biases)

        # classifier = self.conv_op(conv_decode4_1, [3, 3, 64, 2], stride=1, isTraining=isTraining, name='end')
        prediction = self.prediction_result(classifier)

        return prediction

    def prediction_result(self, conv_result):
        # label = tf.cast(label, tf.int32)
        min_val = tf.constant(value=1.0e-10)
        conv_result = tf.reshape(conv_result, (-1, 2))  # 2 represent the class is 2
        conv_result = conv_result + min_val
        softmax = tf.nn.softmax(conv_result)  # (batch_size, height, width, channels)
        return softmax

    def cal_loss(self, prediction, labels):
        class_weight = np.array([1.5, 98.5], dtype='float32')
        min_val = tf.constant(value=1.0e-10)
        with tf.name_scope('loss'):
            labels = tf.reshape(tf.one_hot(labels, depth=2), (-1, 2))

            cross_entropy = -tf.reduce_sum(tf.multiply((labels * tf.log(prediction + min_val)), class_weight),
                                           axis=1)  # [1]
            # cross_entropy = -tf.reduce_sum(tf.multiply(labels, tf.log(prediction + min_val)), axis=1)

            cross_entropy_mean = tf.reduce_mean(cross_entropy, name='cross_entropy')
            tf.add_to_collection('losses', cross_entropy_mean)
            loss = tf.add_n(tf.get_collection('losses'), name='total_losses')
        return loss

    def train(self, batch_size, train_filename, model_path):
        img_batch, label_batch = read_batch(train_filename, batch_size)
        isTrain = tf.constant(True, dtype=tf.bool)

        prediction = self.inference(img_batch, batch_size, isTrain)

        label = tf.reshape(tf.one_hot(label_batch, depth=2), (-1, 2))
        acc_val = tf.equal(tf.arg_max(prediction, 1), tf.arg_max(label, 1))

        accuracy = tf.reduce_mean(tf.cast(acc_val, dtype=tf.float32), name='acc')

        losses = self.cal_loss(prediction, label_batch)

        global_step = tf.Variable(0, trainable=False)
        variable_averages = tf.train.ExponentialMovingAverage(self.moving_average_decay, global_step)
        variables_averages_op = variable_averages.apply(tf.trainable_variables())

        learning_rate = tf.train.exponential_decay(self.learning_rate, global_step,
                                                   1224 / batch_size,
                                                   self.learning_rate_decay)

        train_step = tf.train.AdamOptimizer(learning_rate).minimize(losses, global_step=global_step)
        # train_step = tf.train.GradientDescentOptimizer(self.learning_rate).minimize(loss, global_step=global_step)

        with tf.control_dependencies([train_step, variables_averages_op]):
            train_op = tf.no_op(name='train')

        saver = tf.train.Saver()

        with tf.Session() as sess:
            tf.global_variables_initializer().run()
            tf.local_variables_initializer().run()
            coord = tf.train.Coordinator()
            threads = tf.train.start_queue_runners(sess=sess, coord=coord)

            num = 1224 / batch_size

            for i in range(self.num_epochs):
                print '~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~'
                print time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time()))
                print '~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~'
                print 'Epoch %s/%s ' % (i+1, self.num_epochs)
                for j in range(num):
                    _, setp, acc, loss = sess.run([train_op, global_step, accuracy, losses])
                    if j == 101:
                        print '102/1224   >..................................losses: %s    accuracy: %s' % (loss, acc)
                    elif j == 203:
                        print '204/1224   --->...............................losses: %s    accuracy: %s' % (loss, acc)
                    elif j == 305:
                        print '306/1224   ------>............................losses: %s    accuracy: %s' % (loss, acc)
                    elif j == 407:
                        print '408/1224   --------->.........................losses: %s    accuracy: %s' % (loss, acc)
                    elif j == 509:
                        print '510/1224   ------------>......................losses: %s    accuracy: %s' % (loss, acc)
                    elif j == 611:
                        print '612/1224   --------------->...................losses: %s    accuracy: %s' % (loss, acc)
                    elif j == 713:
                        print '714/1224   ------------------>................losses: %s    accuracy: %s' % (loss, acc)
                    elif j == 815:
                        print '816/1224   --------------------->.............losses: %s    accuracy: %s' % (loss, acc)
                    elif j == 917:
                        print '918/1224   ------------------------>..........losses: %s    accuracy: %s' % (loss, acc)
                    elif j == 1019:
                        print '1020/1224   --------------------------->......losses: %s    accuracy: %s' % (loss, acc)
                    elif j == 1121:
                        print '1122/1224   ------------------------------>...losses: %s    accuracy: %s' % (loss, acc)
                    elif j == 1223:
                        print '1224/1224   ------------------------------>...losses: %s    accuracy: %s' % (loss, acc)

                if (i % 20 == 0) & (i != 0):
                    saver.save(sess, model_path+str(i))

            saver.save(sess, model_path)

            coord.request_stop()
            coord.join(threads)

    def prediction_local_run(self, batch_size, model_path, test_tf_file_path, pre_file_out_path=None):
        isTrain = tf.constant(True, dtype=tf.bool)
        files, images = read_bacth_multifile(test_tf_file_path, batch_size)
        #img_batch, label_batch = read_batch(test_tf_file_path, batch_size)

        prediction = self.inference(images, batch_size, isTrain)
        result = tf.arg_max(prediction, 1)

        #label = tf.reshape(tf.one_hot(label_batch, depth=2), (-1, 2))
        #acc_val = tf.equal(result, tf.arg_max(label, 1))
        #accuracy = tf.reduce_mean(tf.cast(acc_val, dtype=tf.float32), name='acc')

        variable_averages = tf.train.ExponentialMovingAverage(self.moving_average_decay)
        variables_to_restore = variable_averages.variables_to_restore()

        saver = tf.train.Saver(variables_to_restore)

        out_arr = np.zeros((4032, 15232))
        tmp_rows = 0
        with tf.Session() as sess:
            tf.global_variables_initializer().run()
            tf.local_variables_initializer().run()

            coord = tf.train.Coordinator()
            threads = tf.train.start_queue_runners(sess=sess, coord=coord)

            saver.restore(sess, model_path)

            for i in range(1224):
                #pre_result, acc = sess.run([result, accuracy])
                pre_result = sess.run(result)
                #print '%s batch_size---->accuracy: %s' % (i, acc)
                tmp_val = pre_result.reshape(224, 224)
                if (i % 68 == 0) & (i != 0):
                    tmp_rows += 1
                out_arr[tmp_rows * 224: (tmp_rows + 1) * 224, (i%68)*224: (i%68+1)*224] += tmp_val

            coord.request_stop()
            coord.join(threads)

        out_arr = np.array(out_arr, dtype='int32')
        im_arr = out_arr[0: 4000, 0: 15106]
        write_tiff(pre_file_out_path, im_arr, 15106, 4000, 1)

    # run on pai print accuracy
    def prediction(self, batch_size, model_path, test_tf_file_path, pre_file_out_path=None):
        isTrain = tf.constant(True, dtype=tf.bool)
        img_batch, label_batch = read_batch(test_tf_file_path, batch_size)

        prediction = self.inference(img_batch, batch_size, isTrain)
        result = tf.arg_max(prediction, 1)

        label = tf.reshape(tf.one_hot(label_batch, depth=2), (-1, 2))
        acc_val = tf.equal(result, tf.arg_max(label, 1))

        accuracy = tf.reduce_mean(tf.cast(acc_val, dtype=tf.float32), name='acc')

        variable_averages = tf.train.ExponentialMovingAverage(self.moving_average_decay)
        variables_to_restore = variable_averages.variables_to_restore()

        saver = tf.train.Saver(variables_to_restore)

        out_arr = np.zeros((4032, 15232))
        tmp_rows = 0
        with tf.Session() as sess:
            tf.global_variables_initializer().run()
            tf.local_variables_initializer().run()

            coord = tf.train.Coordinator()
            threads = tf.train.start_queue_runners(sess=sess, coord=coord)

            saver.restore(sess, model_path)

            for i in range(1224):
                pre_result, acc = sess.run([result, accuracy])
                print '%s batch_size---->accuracy: %s' % (i, acc)
                tmp_val = pre_result.reshape(224, 224)
                if (i % 68 == 0) & (i != 0):
                    tmp_rows += 1
                out_arr[tmp_rows * 224: (tmp_rows + 1) * 224, (i%68)*224: (i%68+1)*224] += tmp_val

            coord.request_stop()
            coord.join(threads)

        out_arr = np.array(out_arr, dtype='int32')
        out_string = out_arr.tostring()

        tf.gfile.FastGFile(pre_file_out_path, 'wb').write(out_string)

    # run on pai no label compare
    def prediction_no_label(self, batch_size, model_path, test_tf_file_path, pre_file_out_path=None):
        isTrain = tf.constant(True, dtype=tf.bool)
        files, images = read_bacth_multifile(test_tf_file_path, batch_size)

        prediction = self.inference(images, batch_size, isTrain)
        result = tf.arg_max(prediction, 1)

        variable_averages = tf.train.ExponentialMovingAverage(self.moving_average_decay)
        variables_to_restore = variable_averages.variables_to_restore()

        saver = tf.train.Saver(variables_to_restore)

        out_arr = np.zeros((4032, 15232))
        tmp_rows = 0
        with tf.Session() as sess:
            tf.global_variables_initializer().run()
            tf.local_variables_initializer().run()

            coord = tf.train.Coordinator()
            threads = tf.train.start_queue_runners(sess=sess, coord=coord)

            saver.restore(sess, model_path)

            for i in range(1224):
                pre_result = sess.run(result)
                tmp_val = pre_result.reshape(224, 224)
                if (i % 68 == 0) & (i != 0):
                    tmp_rows += 1
                out_arr[tmp_rows * 224: (tmp_rows + 1) * 224, (i%68)*224: (i%68+1)*224] += tmp_val

            coord.request_stop()
            coord.join(threads)

        out_arr = np.array(out_arr, dtype='int32')
        out_string = out_arr.tostring()

        tf.gfile.FastGFile(pre_file_out_path, 'wb').write(out_string)

    # local run make the txt file for generate from the pai to tif file
    def generate_tif_file_from_txt(self, txt_file_in, tif_file_out, geo_file=None):
        txt_read = open(txt_file_in)
        txt_data = txt_read.read()
        im_arr = np.fromstring(txt_data, dtype='int32')
        im_arr = im_arr.reshape(4032, 15232)  # recurrent split large image
        im_arr1 = im_arr[0: 4000, 0: 15106]  # recurrent raw image

        if geo_file:
            im = gdal.Open(geo_file)
            writeTiff(im_arr1, 15106, 4000, 1, tif_file_out, [0, 12, 0, 0, 0, -12], im.GetProjection())
            #writeTiff(im_arr1, 15106, 4000, 1, tif_file_out, im.GetGeoTransform, im.GetProjection())
